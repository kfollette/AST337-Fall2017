{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10 - Calibrating Photometry and Creating a CMD\n",
    "## Names:\n",
    "\n",
    "***\n",
    "\n",
    "## Overview\n",
    "\n",
    "In the previous lab, you extracted aperture photometry for all of the stars in a given image, and experimented with different parameters to understand how identifying stars and measuring their fluxes can change based on how you choose various parameters. This week, we want to use that information to do the following: \n",
    "\n",
    "* Calculate the instrumental magnitudes of the standard stars and M52 stars, based on your flux measurements.  \n",
    "\n",
    "* Determine the _zeropoint_: the difference between the instrumental magnitude of a standard star and its known, calibated magnitude value in a given photometric system.  \n",
    "\n",
    "* Use the zeropoint to calibrate the photometry of the cluster stars.  \n",
    "\n",
    "* Estimate the errors on our measured fluxes, and propagate these errors into our final magnitude calculations.  \n",
    "\n",
    "* Plot a V vs. V-R color-magnitude diagram for M52!\n",
    "\n",
    "\n",
    "## Data for this Lab: M52 Images from Homework 10\n",
    "In this lab, you will work with the aligned V-band and R-band images of M52 that you created for Homework 10. Start by downloading your two final aligned M52 FITS files into this directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 - Identifying the Standard Star\n",
    "\n",
    "\n",
    "We've provided reduced, aligned frames of the standard star for the M52 dataset, **SA 114637**.\n",
    "\n",
    "The first step is to identify the standard star in the provided reduced images. Use iObserve to look up the star and get a DSS image roughly the same size as the Smith detector. You may have to flip the image N-S or E-W to match the orientation of the Smith images. \n",
    "\n",
    "**(1)** Include a screenshot of the DSS image from iObserve below.\n",
    "\n",
    "![DSS Image](your_image.png \"DSS Image\")\n",
    "\n",
    "**(2)** Decide which of the stars in the Smith images (either V or R band -- they are aligned to each other) is the standard star. Check your answer with one other neighboring group. Place a circle region around the star in the Smith image and put a screenshot below.\n",
    "\n",
    "![Smith image](your_image.png \"Smith Image\")\n",
    "\n",
    "**(3)** What are the x-y coordinates of the  standard star in the Smith image?  \n",
    "**Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 - Aperture Photometry on the Standard Star and M52\n",
    "\n",
    "Following the work from the previous lab, you will extract the photometry for each of the final reduced images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The standard fare, plus a few extra packages:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.io.fits as fits\n",
    "import os.path\n",
    "%matplotlib inline\n",
    "\n",
    "# Newer packages:\n",
    "from astropy.stats import mad_std\n",
    "from astropy.stats import sigma_clip\n",
    "from photutils.utils import calc_total_error\n",
    "import astropy.stats as stat\n",
    "\n",
    "from photutils import aperture_photometry, CircularAperture, CircularAnnulus, DAOStarFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Photometry Functions\n",
    "\n",
    "We would like our photometry module to have two functions:  \n",
    "\n",
    "**(1)** A function to extract the stars in a given image,  \n",
    "and  \n",
    "**(2)** A function to perform photometry on that image, with adjustable parameters, which provides errors on the measurements. \n",
    "\n",
    "### Measuring Background Error\n",
    "The first step is to use a new function (provided below) to estimate the background level. Comment this function and add a docstring, and we will apply it shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bg_error_estimate(fitsfile):\n",
    "    \"\"\"\n",
    "    Edit this docstring\n",
    "    \"\"\"\n",
    "    fitsdata = fits.getdata(fitsfile)\n",
    "    hdr = fits.getheader(fitsfile)\n",
    "    \n",
    "    # What is happening in the next step? Read the docstring for sigma_clip.\n",
    "    # Answer:\n",
    "    filtered_data = sigma_clip(fitsdata, sigma=3.,copy=False)\n",
    "    \n",
    "    # Summarize the following steps:\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    bkg_values_nan = filtered_data.filled(fill_value=np.nan)\n",
    "    bkg_error = np.sqrt(bkg_values_nan)\n",
    "    bkg_error[np.isnan(bkg_error)] = np.nanmedian(bkg_error)\n",
    "    \n",
    "    print(\"Writing the background-only error image: \", fitsfile.split('.')[0]+\"_bgerror.fit\")\n",
    "    fits.writeto(fitsfile.split('.')[0]+\"_bgerror.fit\", bkg_error, hdr, overwrite=True)\n",
    "    \n",
    "    effective_gain = 1.4 # electrons per ADU\n",
    "    \n",
    "    error_image = calc_total_error(fitsdata, bkg_error, effective_gain)  \n",
    "    \n",
    "    print(\"Writing the total error image: \", fitsfile.split('.')[0]+\"_error.fit\")\n",
    "    fits.writeto(fitsfile.split('.')[0]+\"_error.fit\", error_image, hdr, overwrite=True)\n",
    "    \n",
    "    return error_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1)**: What is the purpose of the calc_total_error step? How does it relate to the CCD equation? (The docstring and the section on Error Estimation at https://photutils.readthedocs.io/en/stable/aperture.html are helpful resources here.)  \n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (a): Creating functions for a photometry module**\n",
    "\n",
    "In the following two cells are incomplete functions that you will edit and run. You may need to refer to Lab 9 to remember how to complete various steps. Anywhre you see asterisks are places you will need to edit. Comment as necessary -- some places have prompts for you to comment specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Star extraction function -- this function can be to also return the x and y positions to the notebook to use later:\n",
    "\n",
    "# target_filter_xpos, target_filter_ypos = starExtractor(\"image.fit\", nsigma_value=#, fwhm_value=#)\n",
    "\n",
    "def starExtractor(fitsfile, nsigma_value, fwhm_value):\n",
    "    \"\"\"\n",
    "    This is an incomplete function! Asterisks denote a step where you need to complete the code.\n",
    "    Also, replace this with your docstring, including how to use the function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # First, check if the region file exists yet, so it doesn't get overwritten\n",
    "    regionfile = fitsfile.split(\".\")[0] + \".reg\"\n",
    "     \n",
    "    if os.path.exists(regionfile) == True:\n",
    "        print(regionfile, \"already exists in this directory. Rename or remove the .reg file and run again.\")\n",
    "        return\n",
    "    \n",
    "    # *** Read in the data from the fits file ***\n",
    "    image = \n",
    "    \n",
    "    # *** Measure the median absolute standard deviation of the image: ***\n",
    "    bkg_sigma = \n",
    "\n",
    "    # *** Define the parameters for DAOStarFinder ***\n",
    "    daofind = \n",
    "    \n",
    "    # Apply DAOStarFinder to the image\n",
    "    sources = daofind(image)\n",
    "    nstars = len(sources)\n",
    "    print(\"Number of stars found in \",fitsfile,\":\", nstars)\n",
    "    \n",
    "    # Define arrays of x-position and y-position\n",
    "    xpos = np.array(sources['xcentroid'])\n",
    "    ypos = np.array(sources['ycentroid'])\n",
    "    \n",
    "    # Write the positions to a .reg file based on the input file name\n",
    "    if os.path.exists(regionfile) == False:\n",
    "        f = open(regionfile, 'w') \n",
    "        for i in range(0,len(xpos)):\n",
    "            f.write('circle '+str(xpos[i])+' '+str(ypos[i])+' '+str(fwhm_value)+'\\n')\n",
    "        f.close()\n",
    "        print(\"Wrote \", regionfile)\n",
    "        return xpos, ypos # Return the x and y positions of each star as variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Photometry function, which returns a table of photometry values for a list of stars\n",
    "\n",
    "# This function can be used as\n",
    "# target_phot_table = measurePhotometry(file, star_xpos, star_ypos, aperture_radius, sky_inner, sky_outer, error_array)\n",
    "\n",
    "def measurePhotometry(fitsfile, star_xpos, star_ypos, aperture_radius, sky_inner, sky_outer, error_array):\n",
    "    \"\"\"\n",
    "    Add a docstring here. Add comments at the # below\n",
    "    \"\"\"\n",
    "    # *** Read in the data from the fits file:\n",
    "    image = \n",
    "    \n",
    "    starapertures = CircularAperture((star_xpos, star_ypos),r = aperture_radius)\n",
    "    skyannuli = CircularAnnulus((star_xpos, star_ypos), r_in = sky_inner, r_out = sky_outer)\n",
    "    phot_apers = [starapertures, skyannuli]\n",
    "    \n",
    "    # What is new about the way we're calling aperture_photometry?\n",
    "    # *** Add descriptive comments here\n",
    "    phot_table = aperture_photometry(image, phot_apers, error=error_array)\n",
    "        \n",
    "    # Calculate mean background in annulus and subtract from aperture flux\n",
    "    bkg_mean = phot_table['aperture_sum_1'] / skyannuli.area()\n",
    "    bkg_starap_sum = bkg_mean * starapertures.area()\n",
    "    final_sum = phot_table['aperture_sum_0']-bkg_starap_sum\n",
    "    phot_table['bg_subtracted_star_counts'] = final_sum\n",
    "    \n",
    "    # *** Add descriptive comments here.\n",
    "    bkg_mean_err = phot_table['aperture_sum_err_1'] / skyannuli.area()\n",
    "    bkg_sum_err = bkg_mean_err * starapertures.area()\n",
    "    \n",
    "    # *** Add descriptive comments here.\n",
    "    phot_table['bg_sub_star_cts_err'] = np.sqrt((phot_table['aperture_sum_err_0']**2)+(bkg_sum_err**2)) \n",
    "    \n",
    "    return phot_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (b): Extracting photometry for the standard star images**\n",
    "\n",
    "**(1)** Take a look at the standard star images. The data for SA 114637 are not the highest quality. When examining the reduced images, also think back to the conditions during our first observing night at Smith. What factors might be affecting image quality and how?  \n",
    "**Answer:** \n",
    "\n",
    "In the cells below, we will complete the following steps for the reduced standard star V-band image:\n",
    "* Measure the background of the image\n",
    "* Extract the star positions \n",
    "* Use the star positions and background error to measure the photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Measure the background of the image\n",
    "std_V_bgerror = bg_error_estimate(\"std114637_V_stack.fit\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2)**: Open the resulting image, std114637_Vstack_error.fit, in ds9. What do you notice about the image? Describe quantitatively.  \n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract the star positions. Replace ?? with values for the extraction parameters that capture the stars of interest.\n",
    "std_V_xpos, std_V_ypos = starExtractor(\"std114637_V_stack.fit\", nsigma_value=??, fwhm_value=??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3)**: Open the standard star image in ds9 and load the regions it created. Was your standard star identified correctly? If not, why/what did you have to change? (Pause and check at this point.)  \n",
    "**Answer:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Measure photometry for the V band image. Replace ?? with reasonable values\n",
    "std_V_phottable = measurePhotometry(\"std114637_V_stack.fit\", star_xpos=std_V_xpos, star_ypos=std_V_ypos, \\\n",
    "                                    aperture_radius=??, sky_inner=??, sky_outer=??, error_array=std_V_bgerror)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4):** Check the resulting photometry table below. What index is your standard star? (Refer back to the earlier portion of the lab where you measured the standard star position in the image)  \n",
    "**Answer**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print a single row from the array with the standard star only\n",
    "std_V_phottable[??]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells, repeat the above procedure for the standard star image, this time in R band. \n",
    "\n",
    "### Important Note: \n",
    "Now that we have the positions in V band, we can skip the extraction step in the other filter (since the images are aligned to each other!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Measure the background of the R image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Measure photometry for the R band image. \n",
    "# NOTE: Use std_V_xpos and std_V_ypos to extract photometry for the same stars in the same locations & order!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print a single row from the array with the standard star only\n",
    "std_V_phottable[??]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now stitch together the results into a streamlined pandas dataframe, by defining the dataframe index and column labels of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ['id','xcenter', 'ycenter','Vflux','Vfluxerr','Rflux','Rfluxerr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std_fluxtable = pd.DataFrame(\n",
    "    {'id'      : std_V_phottable['id'],\n",
    "     'xcenter' : std_V_phottable['xcenter'],\n",
    "     'ycenter' : std_V_phottable['ycenter'],\n",
    "     'Vflux'   : std_V_phottable['bg_subtracted_star_counts'],\n",
    "     'Vfluxerr': std_V_phottable['bg_sub_star_cts_err'], \n",
    "     'Rflux'   : std_R_phottable['bg_subtracted_star_counts'],\n",
    "     'Rfluxerr': std_R_phottable['bg_sub_star_cts_err']}, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Below, check the dataframe to ensure that the combination worked:\n",
    "std_fluxtable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (c): Extracting photometry for the M52 cluster stars**\n",
    "\n",
    "In the cells below, you will repeat the process with the actual cluster images you made for M52 in both V and R bands. Adjust the function inputs (e.g., star extraction) and the photometry parameters accordingly, and we will also estimate the combined errors in the final image and save these results as FITS files.\n",
    "\n",
    "In the last cell, create a single pandas flux dataframe for the M52 cluster image (`M52_fluxtable`, just like the `std_fluxtable`). We will use these to calibrate the photometry in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# M52 V-band analysis -- add any blank cells as needed\n",
    "\n",
    "# Measure the background of the image\n",
    "M52_V_bgerror ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract the star positions and save them to new variables. \n",
    "# Do you have too few stars? Too many? Check the quality of the extraction.\n",
    "M52_V_xpos, M52_V_ypos ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once you have decided on extraction parameters, include** a screenshot here of the ds9 image of M52 with the regions overlaid.\n",
    "\n",
    "[screenshot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Measure photometry \n",
    "\n",
    "M52_V_phottable = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the M52 photometry table\n",
    "M52_V_phottable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Follow the same approach for the the R band images, using the M52 V band star locations. \n",
    "# Add blank cells below as needed.\n",
    "\n",
    "M52_R_bgerror =\n",
    "M52_R_phottable ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finally, combine the photometry into a single pandas dataframe for M52. \n",
    "\n",
    "M52_fluxtable = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the contents of the new dataframe here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 - Calculating Instrumental Magnitudes and Measuring Zeropoints \n",
    "\n",
    "Note that when calculating zeropoint, units are in *flux per second*, so it's critically important than we divide by exposure time of the image. \n",
    "\n",
    "**(1):** What would happen if we simply compared the measured fluxes without performing this scaling for exposure time first? By what factor would our estimates of the cluster star magnitudes be incorrect?  \n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the relation for instrumental magnitude:\n",
    "\n",
    "$m_{inst} = -2.5 log_{10}(\\textit{flux in 1-second})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part (a):** Update the pandas dataframes for both the standard star and M52 images, by retrieving the exposure times from the FITS headers and adding new columns, \"Vflux_1sec\" and \"Rflux_1sec\", and \"Vflux_1sec_err\" and \"Rflux_1sec_err\":\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code here for the standard star dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check that new columns were added \n",
    "std_fluxtable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here for the M52 dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check that new columns were added \n",
    "M52_fluxtable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (b):** Calculate the instrumental magnitudes (label them \"V_inst\" and \"R_inst\"), and also add these as new columns to your ever-growing standard star **and** M52 dataframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (c):** Propagate errors on the fluxes into errors on the instrumental magnitudes:\n",
    "\n",
    "We discussed in lecture that the uncertainty propagation for log values goes as follows:\n",
    "\n",
    "If $x = k * log(a)$, where is $k$ is a constant value, then we can evaluate the uncertainty on $x$, that is $\\sigma_{x}$ as:\n",
    "\n",
    "$\\sigma_{x} = k * 0.434 \\frac{\\sigma_{a}}{a}$\n",
    "\n",
    "\n",
    "Add these to your two pandas dataframes as new columns,\n",
    "\n",
    "\"Vinst_err\", \"Rinst_err\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the tables again in the following cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the row in the standard star table corresponding to the standard star\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part(d):** Look up the actual magnitude values for SA 114637 using the Simbad Astronomical Database:\n",
    "\n",
    "http://simbad.u-strasbg.fr/simbad/sim-fid\n",
    "\n",
    "**(2)** What are the V and R band magnitudes for this standard star, and what are their uncertainties? (bracketed values)  \n",
    "**Answer:**\n",
    "\n",
    "Now we can use these values for the standard star to determine the zeropoints, as follows:\n",
    "\n",
    "$m_{calibrated} = m_{inst} + zeropoint$\n",
    "\n",
    "So to determine the zeropoints, we will need to propagate uncertainties. (Writing zeropoint as magzp):\n",
    "\n",
    "$magzp \\pm \\sigma_{magzp}$ = ($m_{calib} \\pm \\sigma_{m_{calib}}$) - ($m_{inst} \\pm \\sigma_{m_{inst}}$ )\n",
    "\n",
    "**(3)** How do you calculate the value of $\\sigma_{magzp}$?  \n",
    "**Answer:**\n",
    "\n",
    "First, you'll need to locate the row coresponding to the standard star in the standard star image dataframe. \n",
    "\n",
    "**(4)** What are the V and R band instrumental magnitudes and uncertainties of the standard star?  \n",
    "**Answer:**\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in the cell below calculate the zeropoints for each band. Before proceeding to 10.4, check your method of calculating the uncertainty on each zeropoint from the errors on the insturmental and calibrated magnitudes. After you've estimated the zeropoints, pause here and check your values with us and other groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "magzp_V = \n",
    "\n",
    "magzp_V_error = \n",
    "\n",
    "magzp_R =\n",
    "\n",
    "magzp_R_error = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Zeropoint in V: \", magzp_V, \"+/-\", magzp_V_error)\n",
    "print(\"Zeropoint in R: \", magzp_R, \"+/-\", magzp_R_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4 - Calibrate Cluster Photometry using the Zeropoint Offsets \n",
    "\n",
    "Now that we have the zeropoint values in hand, we can efficiently calibrate all of the fluxes in the cluster dataframe. Write a quick function below that takes in a zeropoint value, its error, and its corresponding filter, then operates on the series in the panda dataframe and adds new columns for the final calibrated magnitude columns and their uncertainties: `Vmag`, `Vmag_err`, `Rmag`, and `Rmag_err`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define your function here\n",
    "def zpcalc(magzp, magzp_err, filtername, dataframe):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply your function to finalize your M52 data table, and show a portion of the dataframe below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply function to dataframes\n",
    "zpcalc(magzp_V, magzp_V_error, \"V\", M52_fluxtable)\n",
    "\n",
    "zpcalc(magzp_R, magzp_R_error, \"R\", M52_fluxtable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at dataframe snippet\n",
    "M52_fluxtable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step for our photometry table is to calculate a color, namely V-R. Add this quantity as a final column with its error calculated from the relative errors on V and R. Then we will write the table to a file and save it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add V-R column and V-R error column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finally, save both calibrated dataframes (standard and M52) here as .csv files;\n",
    "# These can later be read into Excel, Google Sheets, back into pandas, etc. for future use\n",
    "\n",
    "std_fluxtable.to_csv('SA114637_photometry.csv')\n",
    "M52_fluxtable.to_csv('M52_photometry.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!** You have converted your raw FITS datasets into usable science products, and have measured and calibrated the photometry to a magnitude system that is both universally recognized by other astronomers and includes reasonable error estimates. \n",
    "\n",
    "One thing we have not done is compare our estimated calibrated photometry for M52 with the known literature values -- this is something you will explore shortly.\n",
    "\n",
    "Let's see what the data look like!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.5 - Plotting the Color-Magnitude Diagram\n",
    "\n",
    "To plot data with errorbars, we'll use a slightly different plotting method in matplotlib, called `plt.scatter`. It can be used as follows:\n",
    "\n",
    "`plt.errorbar(x_data, y_data, xerr = x_errors, yerr = y_errors, marker = 'o', linestyle='None')`\n",
    "\n",
    "In the cell below, plot the V vs. V-R color-magnitude digram for M52, adjusting the axes as necessary, and adding all relevant labels, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your CMD here:\n",
    "plt.figure(figsize=(10,10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension Questions\n",
    "\n",
    "1) What do you notice about the uncertainties in the dataset?\n",
    "\n",
    "2) How do the median uncertainties compare for the V-band data vs. the R-band data?\n",
    "\n",
    "3) How does this CMD compare to those you created back in Lab 2?\n",
    "\n",
    "4) Are any parts of the H-R diagram missing? Which types of stars appear to be present? Which might be absent? \n",
    "\n",
    "5) What are some potential sources of contamination in our datasets?\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
