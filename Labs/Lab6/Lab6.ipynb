{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6: Working with FITS Image Data and Manipulating Arrays\n",
    "\n",
    "## <u>Names:</u> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of this lab is to create \"master\" calibration frames from the raw calibration frames we took at Smith. Your homework will then involve applying the calibrations you created in this lab to the cluster and standard star images we took, so that you can work with calibrated science frames.\n",
    "\n",
    "To work with the calibration frames, we will learn new methods for organizing files, working with arrays of image data, using the FITS data we took from our first observing night at Smith. Along the way, we will learn to use a few Unix tasks from within Python, and we will use and write a number of functions that we will later use outside of the Jupyter Notebook environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Sorting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you pulled the class Git repository for this lab, you will have also downloaded the zipped folder with all of the FITS files we took at Smith. \n",
    "\n",
    "**First**, unzip this file, which will decompress all of files into a single folder, `2017oct04`.\n",
    "\n",
    "To start working with different groups of images, it will be help to first organize all of those files into subfolders. We will import our usual Python modules and a few others needed for this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The standard fare:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# Recall our use of this module to work with FITS files in Lab 4:\n",
    "from astropy.io import fits \n",
    "\n",
    "# This lets us use various Unix (or Unix-like) commands within Python:\n",
    "import os \n",
    "\n",
    "# We will see what this does shortly.\n",
    "import glob "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Using Glob\n",
    "\n",
    "**glob** is an extremely useful function in Python. First, move into your data directory using `cd`, then `ls` to see the file list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd 2017oct04/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, execute the following two cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_few_files = glob.glob('science*.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_few_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does glob do? What kind of Python object is `a_few_files`?   \n",
    "**Answer**: \n",
    "\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "\n",
    "Now use glob to create a new variable, `all_fits`, that contains the names of **all** of the FITS files in your directory. We will use this variable a number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finish this cell\n",
    "\n",
    "all_fits = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Iterating to View Header Info\n",
    "\n",
    "We now would like to take all of our FITS files and sort them into subfolders based on the type of image, e.g., calibration, science, standard star, etc. Helpfully, the file names include some clues about what sort of files we have. However, if you remember from our observing run and log sheets, not all of the file names are always correct. This can happen _quite easily_ at the telescope, because camera software programs typically have various automated ways of naming files (often different from observatory to observatory) and sometimes require the user to remember to change settings while observing.\n",
    "\n",
    "(To avoid this, some observatories name their files in a uniform way, like \"Image_00001.fits\" or with a time/date stamp, like \"NACO_2017-10-05T00:04:18.fits\", which provide unique identifiers.)\n",
    "\n",
    "Therefore, to check our data and sort it accurately, we'll look at the header information first to get a sense of the type of files we're dealing with. There are a couple different ways we can look at FITS headers; in Lab 4, we used `fits.open`, which is very versatile. Here, we'll use two new functions to quickly view the header and data:\n",
    "\n",
    "`fits.getheader('filename')`\n",
    "\n",
    "and \n",
    "\n",
    "`fits.getdata('filename')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Complete this cell to save the header of the zeroth (that is, the first) FITS file in the all_fits list:\n",
    "\n",
    "test_header = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, view the header info here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use our new variable to view specific header **keyword values**, such as the image type, or object:  \n",
    "(\"IMAGETYP\" and \"OBJECT\", since FITS files can only have 8 character keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_header['IMAGETYP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_header['OBJECT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use `for` loops to iterate over each FITS file in our directory, so we can quickly see what kinds of FITS files we have based on keyword. \n",
    "\n",
    "If iteration is newer to you (or you'd like a brief refresher), check out the other notebook in the main directory ('Unix_Programming_Refresher') for some quick reference exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here is an example for loop that provides all of the image types. \n",
    "# (1) Run this function to view all of the 'IMAGETYP' values, then\n",
    "# (2) Edit and re-run the function to view all of the 'OBJECT' values, then \n",
    "# (3) Edit and re-run once more to view a header keyword value of your choice.\n",
    "\n",
    "for filename in all_fits:\n",
    "    header = fits.getheader(filename)\n",
    "    filetype = header['IMAGETYP']\n",
    "    print(filetype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 The Sorting Function\n",
    "\n",
    "Because data taken in different filters and with different exposure times require matching calibration files, our goal is to create the following directory structure:\n",
    "\n",
    "<img src=\"./folder_flowchart.png\" width='50%'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want a generic function that:\n",
    "\n",
    "(1) takes as input:  \n",
    "* the name of a single FITS file,  \n",
    "* the desired folder name,  \n",
    "* the desired type of FITS file,   \n",
    "* the header keyword to match the FITS file type\n",
    "\n",
    "(2) reads in the file's header information,  \n",
    "\n",
    "(3) reads in the file's type based on the keyword  \n",
    "\n",
    "(4) checks if the desired folder name exists, and makes a new directory if it doesn't  \n",
    "\n",
    "(5) checks if the file's type matches the desired type of fitsfile  \n",
    "\n",
    "(6) moves the file into the new or existing folder, _if_ the file matches the right file type.\n",
    "\n",
    "<br>\n",
    "\n",
    "We've provided a function that does all of these steps, but lacks a docstring. You'll be using this function multiple times, so discuss within your group exactly how the function works, then update the docstring and add comments within the function (using #)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filesorter(filename, foldername, fitskeyword_to_check, keyword):\n",
    "    '''\n",
    "    Edit this docstring to describe the function purpose and use.\n",
    "    '''\n",
    "    if os.path.exists(filename):\n",
    "        pass\n",
    "    else:\n",
    "        print(filename + \" does not exist or has already been moved.\")\n",
    "        return\n",
    "    \n",
    "    header = fits.getheader(filename)\n",
    "    fits_type = header[keyword]\n",
    "    \n",
    "    if os.path.exists(foldername):\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Making new directory: \" + foldername)\n",
    "        os.mkdir(foldername)\n",
    "        \n",
    "    if fits_type == fitskeyword_to_check:\n",
    "        destination = foldername + '/'\n",
    "        print(\"Moving \" + filename + \" to: ./\" + destination + filename)\n",
    "        os.rename(filename, destination + filename)  \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test out the `filesorter` function for a single file, **cal-001_Rflat.fit**. We know this should be a calibration file from the name, but the 'calibration' folder doesn't exist yet, and we can test whether or not it is actually a 'cal' file by checking the 'OBJECT' keyword. \n",
    "\n",
    "Complete and execute the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filesorter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Sort all the calibration data\n",
    "\n",
    "Below, write your own for loop that goes through each file in all_fits, and applies `filesorter` to each file based on your choice of folder name ('calibration'), keyword value, and keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your for loop to sort calibration data here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Move into the calibration folder you created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Re-glob the fits files in the calibration director to a new variable\n",
    "\n",
    "cal_files = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following three cells, use the same for loop structure to make subdirectories for biasframes, darks, and flats. We won't be using 'OBJECT' as the keyword, since that's a more generic category -- decide which keyword is most appropriate here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop to sort flats:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop to sort bias frames:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop to sort dark frames:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Below, list the contents of each subfolder to make sure things moved correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls flats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls biasframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls darks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________\n",
    "\n",
    "## Part 2: Working with Array Data!\n",
    "\n",
    "Now that our calibration data are all sorted into folders, we'll start to work with the raw frames to make the master calibration files.\n",
    "\n",
    "## 2.1 Bias Frames\n",
    "\n",
    "It's simplest to create a master bias frame first, so we'll start with the bias frames. Change directories into your newly-created `biasframes` folder and `ls` to make sure everything has transferred correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd biasframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining bias frame properties\n",
    "\n",
    "The first thing we'll need to do, as before, is to use glob to create a new list of only bias frames to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Complete to create a new bias frame list:\n",
    "\n",
    "biasfiles = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in your reading and in lecture, what we ultimately want is a median combination of all of the individual bias frames. So we will create a stack of bias images, and then we will take the median values at each pixel location in the stack to create the final combined frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Complete: Define a new variable, n, and determine how many bias files there are (length of biasfiles):\n",
    "n = \n",
    "\n",
    "# And use fits.getdata to read in the data for only the first bias frame (the zeroth element of the bias list):\n",
    "first_bias_data = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, our FITS images are 2-D, and we will be working with arrays of various dimensions -- not all FITS images are the same size (e.g. 1024 x 1024). In `numpy`, we can define arrays of various sizes as follows. Execute the cell, and Jupyter will print the formatted version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array([[1, 2, 3],[4, 5, 6],[7, 8, 9]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the shape of the array, we can simply use the .shape command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_array = np.array([[1, 2, 3],[4, 5, 6],[7, 8, 9]])\n",
    "test_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, use this method to determine the dimensions of the first bias image and define them as new variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Complete to get the dimensions of first_bias_data, then check the values\n",
    "\n",
    "imsize_y, imsize_x = \n",
    "imsize_y, imsize_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many bias files are there?  \n",
    "**Answer**:\n",
    "\n",
    "What are the dimensions of the first bias frame?   \n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a blank 3-D array and adding images to it\n",
    "\n",
    "In order to take the median value of the stacked bias frames, we'll need to insert them into a larger array first. We can do this by creating a \"blank\" 3-D array filled with zero values with dimensions of (y dimension, x dimension, number of images):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create blank stack of arrays to hold each of the frames\n",
    "# **IMPORTANT** Note that Y is listed first! This is a pecularity in how python reads arrays:\n",
    "\n",
    "biasarray = np.zeros((imsize_y, imsize_x , n), dtype = np.float32) \n",
    "\n",
    "# Now check the shape of our new \"blank\" array:\n",
    "biasarray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In this cell, check what the values in the biasarray look like now:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make an image **stack** of bias frames by adding the data from each of the FITS files into the \"blank\" stack, one by one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Insert each bias frame into a three dimensional stack, one by one:\n",
    "\n",
    "for ii in range(0, n):\n",
    "    im = fits.getdata(biasfiles[ii])\n",
    "    biasarray[:,:,ii] = im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How do the biasarray values look now?\n",
    "biasarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking the median and saving the master bias:\n",
    "\n",
    "Now the final steps to create a master bias frame are to:\n",
    "\n",
    "(1) take the median of the 3-D array, along the appropriate axis, which will collapse the image to a regular two dimensional array,\n",
    "\n",
    "and \n",
    "\n",
    "(2) save this new 2-D array -- the master bias -- as a brand-new fits file with a new name, giving it the same header as the the first bias image for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take the median of the 3-D stack: \n",
    "med_bias = np.median(biasarray, axis = 2) # axis=2 means stack along the *third* axis, since python is zero-indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And get the header for the first image in the list:\n",
    "biasheader = fits.getheader(biasfiles[0])\n",
    "\n",
    "# Define a name for the new output FITS file:\n",
    "master_bias = 'Master_Bias.fit'\n",
    "\n",
    "# Save your new FITS file!\n",
    "fits.writeto(master_bias, med_bias, biasheader, clobber=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What inputs does the `fits.writeto` function require to save a new FITS files?  \n",
    "**Answer:**\n",
    "\n",
    "\n",
    "The final step is to check the final master bias frame to see if it appears normal. In DS9, open up a single raw calibration bias frame as well as the the new Master_Bias.fit that you just created. \n",
    "\n",
    "How do the two compare? Do the pixel values seem reasonable? Do the dimensions of the image make sense?  \n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median Combination Function\n",
    "For ease of use, let's write all of those proceeding steps into a single function that we can re-use later. Edit the docstring below and add any comments on how to use the function that future you will find helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mediancombine(filelist):\n",
    "    '''\n",
    "    Edit this docstring accordingly!\n",
    "    '''\n",
    "    n = len(filelist)\n",
    "    first_frame_data = fits.getdata(filelist[0])\n",
    "    imsize_y, imsize_x = first_frame_data.shape\n",
    "    fits_stack = np.zeros((imsize_y, imsize_x , n), dtype = np.float32) \n",
    "    for ii in range(0, n):\n",
    "        im = fits.getdata(filelist[ii])\n",
    "        fits_stack[:,:,ii] = im\n",
    "    med_frame = np.median(fits_stack, axis=2)\n",
    "    return med_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now our step to create a median of all the bias frames is much simpler! \n",
    "median_bias = mediancombine(biasfiles)\n",
    "\n",
    "# Below, how would you save the new median_bias frame as a FITS file? \n",
    "# Complete the function below and save the duplicate master bias as \"Backup_MasterBias.fit\")\n",
    "\n",
    "fits.writeto()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One last note on the master bias** -- we will need to determine the path to the Master_Bias.fit file, because we will use functions that call it from different folders. We can do this using os.getcwd (get **c**urrent **w**orking **d**irectory) and adding a string with the filename, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_bias_path = os.getcwd() + '/Master_Bias.fit'\n",
    "master_bias_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Dark Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias subtracting the darks:\n",
    "\n",
    "We want to median combine our darks, but contribution from bias is present in every image taken, so our first step after creating a master bias frame is always to subtract it from every other image. Array subtraction is more straightforward -- as long as two arrays have the same dimension, they can be subtracted from one another on a pixel-by-pixel basis.\n",
    "\n",
    "Below, write a generalized function below that subtracts Master_Bias.fit from a single frame. Your function should: \n",
    "\n",
    "1) take a FITS file name and path to the master bias as inputs,   \n",
    "2) load in the data for the file to be calibrated,  \n",
    "3) loads in the header information for that file,  \n",
    "4) loads in the data for Master_Bias.fit as a variable (remember, it's located in a different folder than where you are now! Hence the second input),  \n",
    "5) subtract the bias from the input FITS file, and  \n",
    "6) save (writeto) the new bias-subtracted FITS file with a modified name (e.g., cal-001_dark60.fit would become b_cal-001_dark60.fit, for bias-subtraction).\n",
    "\n",
    "Once you've written and tested your function, you will apply it to all of the dark frames.\n",
    "\n",
    "The first step is to move into the `darks` directory from your current location and glob the dark files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd ../darks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "darkfiles = glob.glob('*fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your bias subtraction function here:\n",
    "\n",
    "def bias_subtract(filename, path_to_bias):\n",
    "    '''\n",
    "    Add your docstring here.\n",
    "    '''\n",
    "    # Your code goes here.\n",
    "    fits.writeto('b_' + filename, ) # finish this code too to save the FITS\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test out your function on an individual frame (remember, we defined \"master_bias_path\" just before Section 2.2:\n",
    "\n",
    "bias_subtract('cal-001_dark60.fit', master_bias_path)\n",
    "\n",
    "# Did it work? You can test whether the bias subtraction worked by viewing the before/after frames in DS9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now write and execute a for loop that subtracts the bias from each of the dark frames. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have twice the number of dark frames in your directory, half of which have the prefix 'b\\_'. These are the frames we want to median combine into the master dark!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, use the `mediancombine` function from earlier to combine all of the _bias-subtracted_ dark frames into a single master dark. We will call it *Master_Dark_60s.fit* , since dark frames need to match exposure times.\n",
    "\n",
    "**Be careful** using glob to select only the darks that have been bias-subtracted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your lines of code here: \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the master dark compare to a single raw dark frame? Take a look in DS9 and compare:  \n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Flat Fields\n",
    "\n",
    "The final master calibration we want to create is a master flat field (flat). As you may have noticed during our observing night, the features that appear in the flats are highly specific to the filters in which they are taken -- so we will end up with two master flat fields. Therefore, our first steps will be to cd into the flats folder, glob files, and run our `filesorter` function to make the two flat subfolders in our diagram, 'Vband' and 'Rband'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd ../flats/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort by filter into new subfolders below, using the filesorter function and updating its inputs as needed:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll work just with Vband for now, so go into that directory, and you'll work with the Rband reduction in the homework. Like always, our first step is to subtract the master bias. Do this below for all of the files, using your `bias_subtract` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd Vband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Bias-subtract the flat fields:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dark subtract the flat fields:\n",
    "\n",
    "Now, we will want to subtract the dark contribution from the flat fields. This can be accomplished by creating a new function below, `dark_subtract`, that looks very much like your `bias_subtract` function. \n",
    "\n",
    "> * Most importantly, make sure that the dark you subtract matches the exposure time of the flat fields! \n",
    "\n",
    "Check the flat exposure times in the cell below. What is/are the value(s)?  \n",
    "**Answer**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the flat field exposure times here for the files in your directory:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically you would have to scale the 60s master dark to different exposure times, but to save you a bit of effort, we've scaled them for you ahead of time. Both 1s and 10s master dark frames can be found in the \"ExtraFiles\" folder in the top level directory. Copy these files into your 'darks' folder.\n",
    "\n",
    "When you save your dark-subtracted FITS file, be sure to add another prefix to the file name, and it's important to only dark subtract the bias-subtracted images. For example, this would change 'b_cal-001_Vflat.fit' to 'db_cal-001_Vflat.fit'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Copy other master darks to directory in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your dark subtraction function here:\n",
    "\n",
    "def dark_subtract(filename, path_to_dark):\n",
    "    '''\n",
    "    Add your docstring here.\n",
    "    '''\n",
    "    \n",
    "    # Your code goes here.\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now dark subtract the bias-subtracted flat fields:\n",
    "\n",
    "\n",
    "\n",
    "# Did that work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Making a Master Flat Field\n",
    "\n",
    "The final step in creating master calibrations is to make a master flat field. Before we median combine into a single image, we want to divide each individual flat by its median *pixel value*, such that all the pixel values in each frame have values of approximately ~1.0 -- that is, we want to **normalize** them. Only then do we median combine the stack of normalized flat fields to create a master flat.\n",
    "\n",
    "We can do this in a single function by editing the `mediancombine` function from earlier, and simply adding a single new line of code. \n",
    "\n",
    "In line 11 below, add this extra line of code that normalizes `im` before adding it to the 3D array of fits_stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_combine_flats(filelist):\n",
    "    '''\n",
    "    Edit this docstring accordingly!\n",
    "    '''\n",
    "    n = len(filelist)\n",
    "    first_frame_data = fits.getdata(filelist[0])\n",
    "    imsize_y, imsize_x = first_frame_data.shape\n",
    "    fits_stack = np.zeros((imsize_y, imsize_x , n), dtype = np.float32) \n",
    "    for ii in range(0, n):\n",
    "        im = fits.getdata(filelist[ii])\n",
    "        norm_im =  # finish new line here to normalize flats\n",
    "        fits_stack[:,:,ii] = norm_im\n",
    "    med_frame = np.median(fits_stack, axis=2)\n",
    "    return med_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells, run `norm_combine_flats` on your list of dark-subtracted, bias-subtracted frames (only 3 images!), and then check the values of the output to ensure they're close to 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make your list of files first, as usual:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply norm_combine_flats to that list:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at the output of the variable you defined in the previous cell to check the values:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As a final step, finish the code below to save the master flat as a new fits file (Master_Flat_Vband.fit),\n",
    "# with the header taken from the first frame in the flat list.\n",
    "\n",
    "flat_header =\n",
    "\n",
    "fits.writeto('Master_Flat_Vband.fit', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine your master flat file in DS9 and compare it to one of the raw flat frames. What do you notice about the two frames, qualitatively and quantitatively?  \n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
